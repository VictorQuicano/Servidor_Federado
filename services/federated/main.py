import flwr as fl
from typing import Dict, List, Tuple, Optional
import numpy as np
import logging
from flwr.server.strategy import FedAvg
from flwr.common import Parameters, Scalar, FitIns
import torch
import json
import os

import os
import requests
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

MONITORING_API = "http://localhost:8083"

class MonitoringClient:
    def __init__(self, api_url=MONITORING_API):
        self.api_url = api_url
        
    def start_session(self, total_rounds: int) -> int:
        try:
            resp = requests.post(f"{self.api_url}/training/start", json={"total_rounds": total_rounds})
            if resp.status_code == 200:
                return resp.json()["session_id"]
        except Exception as e:
            logging.error(f"Error iniciando sesi√≥n de monitoreo: {e}")
        return -1

    def end_session(self, session_id: int):
        try:
            requests.post(f"{self.api_url}/training/{session_id}/end")
        except:
            pass

    def log_global_metrics(self, session_id: int, round_num: int, metrics: Dict):
        try:
            requests.post(
                f"{self.api_url}/training/{session_id}/round/global",
                json={"round_number": round_num, "metrics": metrics}
            )
        except Exception as e:
            logging.error(f"Error enviando m√©tricas globales: {e}")

class DDPGFedAvg(FedAvg):
    def __init__(self, session_id: int = -1, save_path: str = "federated_metrics.json", *args, **kwargs):
        self.save_path = save_path
        self.session_id = session_id
        self.metrics_history = []
        self.monitor = MonitoringClient()
        super().__init__(*args, **kwargs)
    
    def aggregate_fit(self, server_round, results, failures):
        """Agregar resultados del entrenamiento de clientes"""
        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)
        
        if aggregated_parameters is not None:
            # Calcular m√©tricas promedio de los clientes
            val_rewards = []
            train_losses = []
            actor_losses = []
            
            for client, fit_res in results:
                metrics = fit_res.metrics
                if metrics:
                    val_rewards.append(metrics.get("val_reward", 0.0))
                    train_losses.append(metrics.get("train_loss", 1.0))
                    actor_losses.append(metrics.get("actor_loss", 0.0))
            
            # Estad√≠sticas de par√°metros (para verificar si el modelo cambia)
            if aggregated_parameters:
                ndarrays = fl.common.parameters_to_ndarrays(aggregated_parameters)
                norms = [np.linalg.norm(arr) for arr in ndarrays]
                avg_norm = np.mean(norms)
                logging.info(f"[Ronda {server_round}] Norma promedio de pesos: {avg_norm:.4f}")

            if val_rewards:
                avg_val_reward = np.mean(val_rewards)
                avg_train_loss = np.mean(train_losses)
                avg_actor_loss = np.mean(actor_losses)
                
                logging.info(f"üìä [Ronda {server_round}] RESUMEN:")
                logging.info(f"   ‚Ä¢ Recompensa Val: {avg_val_reward:.4f}")
                logging.info(f"   ‚Ä¢ Critic Loss: {avg_train_loss:.4f}")
                logging.info(f"   ‚Ä¢ Actor Loss: {avg_actor_loss:.4f}")
                
                # Actualizar m√©tricas agregadas
                if aggregated_metrics is None:
                    aggregated_metrics = {}
                aggregated_metrics["avg_val_reward"] = float(avg_val_reward)
                aggregated_metrics["avg_train_loss"] = float(avg_train_loss)
                aggregated_metrics["avg_actor_loss"] = float(avg_actor_loss)

                # Guardar en el historial para el JSON
                self.metrics_history.append({
                    "round": server_round,
                    "avg_val_reward": float(avg_val_reward),
                    "avg_train_loss": float(avg_train_loss),
                    "avg_actor_loss": float(avg_actor_loss),
                    "weight_norm": float(avg_norm) if 'avg_norm' in locals() else 0.0
                })
                self._save_metrics()
                
                # Enviar al sistema de monitoreo
                if self.session_id != -1:
                    self.monitor.log_global_metrics(
                        self.session_id, 
                        server_round, 
                        aggregated_metrics
                    )
        
        return aggregated_parameters, aggregated_metrics

    def _save_metrics(self):
        """Guarda el historial de m√©tricas en un archivo JSON"""
        try:
            with open(self.save_path, "w") as f:
                json.dump(self.metrics_history, f, indent=4)
        except Exception as e:
            logging.error(f"Error al guardar m√©tricas: {e}")
    
    def configure_fit(self, server_round, parameters, client_manager):
        """Configurar entrenamiento para cada cliente - Versi√≥n actualizada"""
        # Configurar par√°metros para esta ronda
        config = {
            "server_round": server_round,
            "session_id": self.session_id,  # Pasar ID de sesi√≥n a clientes
            "local_epochs": 5,
            "epsilon_start": max(0.9 * (0.95 ** (server_round - 1)), 0.1),
            "epsilon_end": 0.1,
            "epsilon_decay": 0.995,
        }
        
        # Obtener clientes para esta ronda
        sample_size, min_num_clients = self.num_fit_clients(
            client_manager.num_available()
        )
        clients = client_manager.sample(
            num_clients=sample_size,
            min_num_clients=min_num_clients
        )
        
        # Crear instrucciones de entrenamiento para cada cliente
        fit_instructions = []
        for client in clients:
            fit_ins = FitIns(parameters, config)
            fit_instructions.append((client, fit_ins))
        
        return fit_instructions
    
    def configure_evaluate(self, server_round, parameters, client_manager):
        """Configurar evaluaci√≥n para cada cliente"""
        config = {
            "server_round": server_round,
            "session_id": self.session_id
        }
        
        # Obtener clientes para evaluaci√≥n
        sample_size, min_num_clients = self.num_evaluation_clients(
            client_manager.num_available()
        )
        clients = client_manager.sample(
            num_clients=sample_size,
            min_num_clients=min_num_clients
        )
        
        # Crear instrucciones de evaluaci√≥n
        evaluate_instructions = []
        for client in clients:
            evaluate_ins = fl.common.EvaluateIns(parameters, config)
            evaluate_instructions.append((client, evaluate_ins))
        
        return evaluate_instructions

def get_initial_parameters() -> Parameters:
    """Inicializar par√°metros del modelo global"""
    # Crear modelos dummy para obtener la estructura
    # IMPORTANTE: Importa aqu√≠ para evitar dependencias circulares
    try:
        from libs.model import ContextAwareActor, ContextAwareCritic
        
        actor = ContextAwareActor(embedding_dim=64)
        critic = ContextAwareCritic(action_dim=64)
        
        # Combinar par√°metros
        params = []
        for model in [actor, critic]:
            params.extend([val.cpu().numpy() for _, val in model.state_dict().items()])
        
        return fl.common.ndarrays_to_parameters(params)
    except ImportError:
        # Si no se pueden importar los modelos, crear par√°metros dummy
        logging.warning("No se pudieron importar los modelos, usando par√°metros dummy")
        # Crear par√°metros dummy basados en dimensiones esperadas
        import numpy as np
        
        # Estimaci√≥n de tama√±o de par√°metros para actor y cr√≠tico
        # Ajusta estos tama√±os seg√∫n tu arquitectura real
        dummy_params = [
            np.random.randn(64, 64).astype(np.float32),  # Capa 1 actor
            np.random.randn(64).astype(np.float32),      # Bias capa 1 actor
            np.random.randn(64, 64).astype(np.float32),  # Capa 2 actor
            np.random.randn(64).astype(np.float32),      # Bias capa 2 actor
            np.random.randn(64, 64).astype(np.float32),  # Capa 1 cr√≠tico
            np.random.randn(64).astype(np.float32),      # Bias capa 1 cr√≠tico
        ]
        
        return fl.common.ndarrays_to_parameters(dummy_params)

def evaluate_metrics_aggregation_fn(results):
    """Funci√≥n para agregar m√©tricas de evaluaci√≥n"""
    metrics_list = [m for _, m in results if m]
    if not metrics_list:
        return {}
    
    aggregated = {
        "avg_val_reward": float(np.mean([m.get("val_reward", 0.0) for m in metrics_list])),
        "avg_precision@5": float(np.mean([m.get("precision@5", 0.0) for m in metrics_list])),
        "avg_ndcg@5": float(np.mean([m.get("ndcg@5", 0.0) for m in metrics_list])),
    }
    
    logging.info(f"üìà [EVALUACI√ìN] Recompensa: {aggregated['avg_val_reward']:.4f}, NDCG@5: {aggregated['avg_ndcg@5']:.4f}")
    return aggregated

def fit_metrics_aggregation_fn(results):
    """Funci√≥n para agregar m√©tricas de entrenamiento (fit)"""
    metrics_list = [m for _, m in results if m]
    if not metrics_list:
        return {}
    
    aggregated = {
        "avg_train_loss": float(np.mean([m.get("train_loss", 0.0) for m in metrics_list])),
        "avg_actor_loss": float(np.mean([m.get("actor_loss", 0.0) for m in metrics_list])),
        "avg_val_reward": float(np.mean([m.get("val_reward", 0.0) for m in metrics_list])),
    }
    return aggregated

def main():
    """Funci√≥n principal del servidor - Versi√≥n actualizada"""
    
    # Iniciar sesi√≥n de monitoreo
    monitor = MonitoringClient()
    session_id = monitor.start_session(total_rounds=5)
    logging.info(f"Sesi√≥n de monitoreo iniciada: {session_id}")
    
    # Definir estrategia con session_id
    strategy = DDPGFedAvg(
        session_id=session_id,
        fraction_fit=0.5,  # Fracci√≥n de clientes para entrenamiento
        fraction_evaluate=0.5,  # Fracci√≥n de clientes para evaluaci√≥n
        min_fit_clients=2,  # M√≠nimo de clientes para entrenamiento
        min_evaluate_clients=2,  # M√≠nimo de clientes para evaluaci√≥n
        min_available_clients=2,  # M√≠nimo de clientes disponibles
        initial_parameters=get_initial_parameters(),
        evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,
        fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,
    )
    
    # Configurar servidor
    server_config = fl.server.ServerConfig(num_rounds=2)
    
    # Usar el m√©todo recomendado para versiones nuevas
    # Opci√≥n 1: Usar el m√©todo nuevo recomendado
    try:
        # Para Flower 1.5+ con la nueva API
        fl.server.start_server(
            server_address="0.0.0.0:8080",
            config=server_config,
            strategy=strategy,
            grpc_max_message_length=1024*1024*1024  # 1GB para modelos grandes
        )
    except TypeError as e:
        # Fallback para versiones ligeramente diferentes
        logging.warning(f"Intentando m√©todo alternativo: {e}")
        fl.server.start_server(
            server_address="0.0.0.0:8080",
            config=server_config,
            strategy=strategy
        )
    monitor.end_session(session_id)
    logging.info(f" Sesi√≥n de monitoreo finalizada: {session_id}")

if __name__ == "__main__":
    main()

    